{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your name:\n",
    "\n",
    "<pre> Jivitesh Shah</pre>\n",
    "\n",
    "### Title:\n",
    "\n",
    "<pre> Here we study the theroy and implementation for K Nearest Neighbours </pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown referece can be found here:\n",
    "    http://nestacms.com/docs/creating-content/markdown-cheat-sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Why would it be a problem if our training set and test set are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> If the training and test set are the same, our model would perform well on the training as well as test set but might not permorm well on new data set. In order for us to have our model perform well on new data, it is advisable to use training set for training the model, a different validation set for validating the model and finally a new testing set to test the model. </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Explain step by step the process to select k in the k-nearest neighbor algorithm (pseudocode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> \n",
    "In order for us to select the best possible k in k-nearest neighbor algorithm, we perfom cross validation on training set and run KNN on that. We can use K Fold cross validation to select optimal k, as shown below:\n",
    "\n",
    "#From training set, split data into K folds, creating a kFolds array\n",
    "kFolds[] = training_set\n",
    "#create kList, a list of random k's for KNN\n",
    "kList[] = random(1,10)\n",
    "\n",
    "#Run KNN on the split data. In each iteration, 1st fold is treated as validation set and remaining k-1 as training set\n",
    "for each k in kList\n",
    "    run KNN on k-1 kFolds[]\n",
    "    fit KNN on the 1st kFold[] as Validation set\n",
    "    calculate error and store in error array\n",
    "    move kFold pointer by 1 so now we use a different sets as validation and training \n",
    "From the list of error, select the min, the k corresponding to that mean is our optimal K in KNN\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. For the k-nearest regression. What happends when k = n. Where n is equal tot he training size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> If we set k = n, we may end up looking at samples that are not neighbours. </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Define a function that takes a 1-d numpy array, a parameter k, and a number p.\n",
    "The function returns an estimate equal to the mean of the closest k points to the number p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the question, it is understood to return the mean of calculated k points to the number p\n",
    "# For this, I will calculate the absolute value for each element in the array and pick smalled k points and return the mean\n",
    "from heapq import nsmallest\n",
    "def k_neighbor(s, k, p):\n",
    "    return np.mean(nsmallest (k, s, key=lambda x: abs(x-p)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "14.0\n",
      "26.0\n",
      "40.0\n",
      "31.333333333333332\n",
      "19.6\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "data = np.array([1,3,4,5,7,8,11,12,13,15,19,24,25,29,40])\n",
    "print(k_neighbor(s=data, k=3, p=5))\n",
    "print(k_neighbor(s=data, k=2, p=15))\n",
    "print(k_neighbor(s=data, k=3, p=25))\n",
    "print(k_neighbor(s=data, k=1, p=55))\n",
    "print(k_neighbor(s=data, k=3, p=55))\n",
    "print(k_neighbor(s=data, k=10, p=55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on nsmallest documentation, it makes a single pass over the data, keeping no more than k best values in memory each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Similar to Q4 but for the n dimentional case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def l1_norm(a,b):\n",
    "    \"\"\"Returns the l1 norm (a,b)\"\"\"\n",
    "    return np.sum(np.abs(a - b))\n",
    "    \n",
    "def l2_norm(a,b):\n",
    "    \"\"\"Returns the l2 norm (a,b)\"\"\" \n",
    "    return np.sqrt(np.sum(np.square(a - b)))\n",
    " \n",
    "def k_neighbor_nd(input_data, k, p, metric='l1', mode='mean'):\n",
    "    \"\"\"Returns the k-neighbor estimate for p using data input_data.\n",
    "\n",
    "    Keyword arguments:\n",
    "    input_data -- numpy array of all the data\n",
    "    k -- Number of k\n",
    "    p -- input values\n",
    "    metric -- l1 or l2. l1 norm or l2 norm https://en.wikipedia.org/wiki/Norm_(mathematics)\n",
    "    mode -- estimator possible values = 'mean', 'median', 'max'\n",
    "    \n",
    "    Implement the l1 and l2 norms\n",
    "    for mean, median and max, use np.mean, np.median and np.max\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    for i in range(len(input_data)):\n",
    "        if (metric == 'l1'):\n",
    "            distance = l1_norm(input_data[i,:],p)\n",
    "        else:\n",
    "            distance = l2_norm(input_data[i,:],p)\n",
    "        distances.append([distance, i])\n",
    "        \n",
    "    distances = sorted(distances)\n",
    "    \n",
    "    output = []\n",
    "    for i in range(k):\n",
    "        index = distances[i][1]\n",
    "        output.append(input_data[index])\n",
    "\n",
    "    if (mode == 'mean'):\n",
    "        return np.mean(output, axis = 1)\n",
    "    elif (mode == 'median'):\n",
    "        return np.median(output, axis = 1)\n",
    "    else:\n",
    "        return np.amax(output, axis = 1)\n",
    "    \n",
    "    #return answer\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4d = np.array([[4, 1, 2, 1], [1, 4, 2, 0], [3, 3, 1, 1], \n",
    "        [4, 0, 0, 0], [1, 2, 0, 0], [3, 4, 2, 3], \n",
    "        [2, 4, 4, 2], [2, 1, 4, 1], [3, 3, 2, 4], \n",
    "        [4, 3, 0, 4], [2, 2, 4, 0],[4, 3, 0, 2], \n",
    "        [4, 3, 0, 2], [0, 3, 4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 2.]\n",
      "[2.25 2.25]\n",
      "[4 4 4]\n",
      "[3.]\n",
      "[3. 3. 3.]\n",
      "[2.   2.25 3.  ]\n",
      "[2.   2.25]\n",
      "[4 4 4]\n",
      "[3.]\n",
      "[3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate   \n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 1, 4, 3], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=2, p=[4, 4, 0, 0], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 2, 2, 4], metric='l1', mode='max'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=1, p=[2, 3, 3, 4], metric='l1', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 3, 3, 4], metric='l1', mode='median'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 1, 4, 3], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=2, p=[4, 4, 0, 0], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 2, 2, 4], metric='l2', mode='max'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=1, p=[2, 3, 3, 4], metric='l2', mode='mean'))\n",
    "print(k_neighbor_nd(input_data=data_4d, k=3, p=[2, 3, 3, 4], metric='l2', mode='median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above implementation, we calculate the distance of each element in the 4D Vector with p, either L1 or L2, sort the distances in ascending order and then return the mean, median or max of each target values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Read the documentation on KNeighborsRegressor\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "    \n",
    "Explore the source code:\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/ef5cb84a/sklearn/neighbors/regression.py\n",
    "        \n",
    "How different it is from your implementation? How well can you follow the code? Did you learn something new?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>The current implementation is not very different from the implementation of KNeighborsRegressor. Both implementations consider mean distance, uniform weights and are used for continuous data labels. \n",
    "\n",
    "It was difficult at first to follow the code on the github page without having prior python experience, but after spending some time with the documentations, I understood the implementation of KNN Regressor.\n",
    "\n",
    "Lastly, I did learn variations in kNN, cross validation to find optimal k and regression and classification.\n",
    "I also learnt different kNN algorithms such as KDTree and BallTree</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
